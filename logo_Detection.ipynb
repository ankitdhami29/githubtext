{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankitdhami29/Bike-Demand-Prediction-Model/blob/main/logo_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEGga5fxJlLP",
        "outputId": "c35bcc73-6e0d-405d-9815-d123ef481b6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Apr 22 09:35:20 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YP0pMqiTpOvM"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Rhvr59dmNxw"
      },
      "outputs": [],
      "source": [
        "!unzip -q /content/data.zip -d /content/custom_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25XvR53BcKCd"
      },
      "outputs": [],
      "source": [
        "!wget -O /content/train_val_split.py https://raw.githubusercontent.com/EdjeElectronics/Train-and-Deploy-YOLO-Models/refs/heads/main/utils/train_val_split.py\n",
        "\n",
        "# !python train_val_split.py --datapath=\"/content/custom_data\" --train_pct=0.9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQoz5DaFCKWd"
      },
      "outputs": [],
      "source": [
        "# !pip install ultralytics"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**# For training model**"
      ],
      "metadata": {
        "id": "FW1P_xe1ZY6g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6530f6aoMykv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import yaml\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from ultralytics import YOLO\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Configuration\n",
        "ORIG_IMAGE_DIR = Path(\"/content/content/content/images\")\n",
        "ORIG_LABEL_DIR = Path(\"/content/content/content/labels\")\n",
        "CLASSES_FILE = Path(\"/content/content/content/classes.txt\")\n",
        "YOLO_DATA_DIR = Path(\"/content/content/content/yolo_dataset\")\n",
        "TRAIN_RATIO = 0.8\n",
        "MODEL_NAME = 'yolov8s.pt'\n",
        "EPOCHS = 80\n",
        "IMG_SIZE = 640\n",
        "BATCH_SIZE = 8\n",
        "INITIAL_LR = 0.01\n",
        "FINAL_LR = 0.01\n",
        "\n",
        "def find_image_path(image_dir, basename):\n",
        "    supported_formats = ('.jpg', '.jpeg', '.png', '.bmp', '.gif', '.webp')\n",
        "    for ext in supported_formats:\n",
        "        path_lower = image_dir / f\"{basename}{ext.lower()}\"\n",
        "        if path_lower.exists():\n",
        "            return path_lower\n",
        "        path_upper = image_dir / f\"{basename}{ext.upper()}\"\n",
        "        if path_upper.exists():\n",
        "            return path_upper\n",
        "    return None\n",
        "\n",
        "def polygon_to_yolo_bbox(polygon_coords_norm):\n",
        "    if len(polygon_coords_norm) < 2 or len(polygon_coords_norm) % 2 != 0:\n",
        "        return None\n",
        "    x_coords = np.array(polygon_coords_norm[0::2])\n",
        "    y_coords = np.array(polygon_coords_norm[1::2])\n",
        "    x_min, x_max = np.min(x_coords), np.max(x_coords)\n",
        "    y_min, y_max = np.min(y_coords), np.max(y_coords)\n",
        "    center_x = (x_min + x_max) / 2.0\n",
        "    center_y = (y_min + y_max) / 2.0\n",
        "    width = x_max - x_min\n",
        "    height = y_max - y_min\n",
        "    return center_x, center_y, width, height\n",
        "\n",
        "# Prepare Directory Structure\n",
        "print(\"Creating directory structure...\")\n",
        "train_img_dir = YOLO_DATA_DIR / \"images\" / \"train\"\n",
        "val_img_dir = YOLO_DATA_DIR / \"images\" / \"val\"\n",
        "train_label_dir = YOLO_DATA_DIR / \"labels\" / \"train\"\n",
        "val_label_dir = YOLO_DATA_DIR / \"labels\" / \"val\"\n",
        "shutil.rmtree(YOLO_DATA_DIR, ignore_errors=True)\n",
        "train_img_dir.mkdir(parents=True, exist_ok=True)\n",
        "val_img_dir.mkdir(parents=True, exist_ok=True)\n",
        "train_label_dir.mkdir(parents=True, exist_ok=True)\n",
        "val_label_dir.mkdir(parents=True, exist_ok=True)\n",
        "print(f\"Created: {YOLO_DATA_DIR}\")\n",
        "\n",
        "# Read Class Names\n",
        "print(f\"Reading class names from {CLASSES_FILE}...\")\n",
        "if not CLASSES_FILE.exists():\n",
        "    raise FileNotFoundError(f\"Error: classes.txt not found at {CLASSES_FILE}\")\n",
        "with open(CLASSES_FILE, 'r') as f:\n",
        "    class_names = [line.strip() for line in f if line.strip()]\n",
        "num_classes = len(class_names)\n",
        "if num_classes == 0:\n",
        "    raise ValueError(f\"Error: No class names found in {CLASSES_FILE}\")\n",
        "print(f\"Found {num_classes} classes: {class_names}\")\n",
        "\n",
        "# List & Split Data\n",
        "print(\"Listing and splitting data...\")\n",
        "image_basenames = []\n",
        "if not ORIG_IMAGE_DIR.is_dir() or not ORIG_LABEL_DIR.is_dir():\n",
        "    raise FileNotFoundError(f\"Error: Original image ({ORIG_IMAGE_DIR}) or label ({ORIG_LABEL_DIR}) directory not found.\")\n",
        "supported_img_formats = ('.jpg', '.jpeg', '.png', '.bmp', '.gif', '.webp')\n",
        "for label_file in ORIG_LABEL_DIR.glob(\"*.txt\"):\n",
        "    basename = label_file.stem\n",
        "    found_image = False\n",
        "    for ext in supported_img_formats:\n",
        "        if (ORIG_IMAGE_DIR / f\"{basename}{ext.lower()}\").exists() or \\\n",
        "           (ORIG_IMAGE_DIR / f\"{basename}{ext.upper()}\").exists():\n",
        "            image_basenames.append(basename)\n",
        "            found_image = True\n",
        "            break\n",
        "if not image_basenames:\n",
        "    raise ValueError(f\"Error: No matching image/label pairs found in {ORIG_IMAGE_DIR} and {ORIG_LABEL_DIR}\")\n",
        "print(f\"Found {len(image_basenames)} matching image/label pairs.\")\n",
        "random.shuffle(image_basenames)\n",
        "split_index = int(len(image_basenames) * TRAIN_RATIO)\n",
        "train_basenames = image_basenames[:split_index]\n",
        "val_basenames = image_basenames[split_index:]\n",
        "print(f\"Splitting into {len(train_basenames)} train and {len(val_basenames)} validation samples.\")\n",
        "\n",
        "# Process Data\n",
        "print(\"Processing training data...\")\n",
        "for basename in tqdm(train_basenames, desc=\"Train\"):\n",
        "    orig_img_path = find_image_path(ORIG_IMAGE_DIR, basename)\n",
        "    orig_label_path = ORIG_LABEL_DIR / f\"{basename}.txt\"\n",
        "    if orig_img_path and orig_label_path.exists():\n",
        "        dest_img_path = train_img_dir / orig_img_path.name\n",
        "        dest_label_path = train_label_dir / f\"{basename}.txt\"\n",
        "        shutil.copy2(orig_img_path, dest_img_path)\n",
        "        with open(orig_label_path, 'r') as infile, open(dest_label_path, 'w') as outfile:\n",
        "            for line in infile:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) >= 3 and len(parts) % 2 != 0:\n",
        "                    try:\n",
        "                        class_id = int(parts[0])\n",
        "                        polygon_coords_norm = [float(p) for p in parts[1:]]\n",
        "                        yolo_bbox = polygon_to_yolo_bbox(polygon_coords_norm)\n",
        "                        if yolo_bbox:\n",
        "                            center_x, center_y, width, height = yolo_bbox\n",
        "                            outfile.write(f\"{class_id} {center_x:.6f} {center_y:.6f} {width:.6f} {height:.6f}\\n\")\n",
        "                    except ValueError:\n",
        "                        continue\n",
        "\n",
        "print(\"Processing validation data...\")\n",
        "for basename in tqdm(val_basenames, desc=\"Validation\"):\n",
        "    orig_img_path = find_image_path(ORIG_IMAGE_DIR, basename)\n",
        "    orig_label_path = ORIG_LABEL_DIR / f\"{basename}.txt\"\n",
        "    if orig_img_path and orig_label_path.exists():\n",
        "        dest_img_path = val_img_dir / orig_img_path.name\n",
        "        dest_label_path = val_label_dir / f\"{basename}.txt\"\n",
        "        shutil.copy2(orig_img_path, dest_img_path)\n",
        "        with open(orig_label_path, 'r') as infile, open(dest_label_path, 'w') as outfile:\n",
        "            for line in infile:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) >= 3 and len(parts) % 2 != 0:\n",
        "                    try:\n",
        "                        class_id = int(parts[0])\n",
        "                        polygon_coords_norm = [float(p) for p in parts[1:]]\n",
        "                        yolo_bbox = polygon_to_yolo_bbox(polygon_coords_norm)\n",
        "                        if yolo_bbox:\n",
        "                            center_x, center_y, width, height = yolo_bbox\n",
        "                            outfile.write(f\"{class_id} {center_x:.6f} {center_y:.6f} {width:.6f} {height:.6f}\\n\")\n",
        "                    except ValueError:\n",
        "                        continue\n",
        "print(\"Data processing complete.\")\n",
        "\n",
        "# Create data.yaml\n",
        "print(\"Creating data.yaml...\")\n",
        "data_yaml_path = YOLO_DATA_DIR / \"data.yaml\"\n",
        "data_config = {\n",
        "    'path': str(YOLO_DATA_DIR.resolve()),\n",
        "    'train': str((YOLO_DATA_DIR / \"images\" / \"train\").resolve()),\n",
        "    'val': str((YOLO_DATA_DIR / \"images\" / \"val\").resolve()),\n",
        "    'nc': num_classes,\n",
        "    'names': class_names\n",
        "}\n",
        "with open(data_yaml_path, 'w') as f:\n",
        "    yaml.dump(data_config, f, default_flow_style=False, sort_keys=False)\n",
        "print(f\"Created {data_yaml_path}\")\n",
        "print(\"--- data.yaml content ---\")\n",
        "with open(data_yaml_path, 'r') as f:\n",
        "    print(f.read())\n",
        "print(\"-------------------------\")\n",
        "\n",
        "# Train the Model\n",
        "print(\"\\nStarting YOLOv8 training...\")\n",
        "print(f\"Using model: {MODEL_NAME}\")\n",
        "print(f\"Epochs: {EPOCHS}, Image Size: {IMG_SIZE}, Batch Size: {BATCH_SIZE}\")\n",
        "print(f\"Optimizer: AdamW, Initial LR: {INITIAL_LR}, Augmentation: Enabled\")\n",
        "\n",
        "model = YOLO(MODEL_NAME)\n",
        "\n",
        "try:\n",
        "    results = model.train(\n",
        "        data=str(data_yaml_path),\n",
        "        epochs=EPOCHS,\n",
        "        imgsz=IMG_SIZE,\n",
        "        batch=BATCH_SIZE,\n",
        "        optimizer='AdamW',\n",
        "        lr0=INITIAL_LR,\n",
        "        lrf=FINAL_LR,\n",
        "        augment=True,\n",
        "        degrees=10,\n",
        "        translate=0.1,\n",
        "        scale=0.2,\n",
        "        shear=0.2,\n",
        "        project='YOLOv8_Training',\n",
        "        name='my_custom_run_adamw_aug'\n",
        "    )\n",
        "    print(\"\\nTraining finished!\")\n",
        "    print(f\"Check for training results in: YOLOv8_Training/my_custom_run_adamw_aug\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nAn error occurred during training: {e}\")\n",
        "    print(\"Check GPU memory (try lowering batch size), file paths, and hyperparameters.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZXs6ydeMyg0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test trained ***model***"
      ],
      "metadata": {
        "id": "D38J_Giqc3Wo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Configuration\n",
        "MODEL_WEIGHTS_PATH = \"/content/content/content/YOLOv8_Training/my_custom_run/weights/best.pt\"\n",
        "INPUT_PATH = \"/content/content/content/test\"\n",
        "OUTPUT_DIR = \"/content/inference_results\"\n",
        "CONF_THRESHOLD = 0.1\n",
        "\n",
        "# Main Execution\n",
        "model_path = Path(MODEL_WEIGHTS_PATH)\n",
        "input_path = Path(INPUT_PATH)\n",
        "output_dir = Path(OUTPUT_DIR)\n",
        "supported_formats = ('.jpg', '.jpeg', '.png', '.bmp', '.webp', '.gif')\n",
        "\n",
        "print(\"--- Script Start ---\")\n",
        "print(f\"Model Path: {model_path}\")\n",
        "print(f\"Input Path: {input_path}\")\n",
        "print(f\"Output Dir: {output_dir}\")\n",
        "\n",
        "if not model_path.exists():\n",
        "    print(f\"Error: Model weights not found at {model_path}\")\n",
        "    exit()\n",
        "\n",
        "if not input_path.exists():\n",
        "    print(f\"Error: Input path not found at {input_path}\")\n",
        "    exit()\n",
        "\n",
        "output_dir.mkdir(parents=True, exist_ok=True)\n",
        "print(f\"Output directory ensured: {output_dir}\")\n",
        "\n",
        "# Identify Image Files\n",
        "print(\"\\n--- Identifying Image Files ---\")\n",
        "print(f\"Supported formats: {supported_formats}\")\n",
        "\n",
        "image_files = []\n",
        "if input_path.is_file():\n",
        "    if input_path.suffix.lower() in supported_formats:\n",
        "        image_files.append(input_path)\n",
        "        print(f\"Added single file: {input_path.name}\")\n",
        "    else:\n",
        "        print(f\"Error: Input file {input_path} is not a supported image format.\")\n",
        "        exit()\n",
        "elif input_path.is_dir():\n",
        "    print(f\"Input path is a directory. Scanning...\")\n",
        "    for item in input_path.iterdir():\n",
        "        if item.is_file() and item.suffix.lower() in supported_formats:\n",
        "            image_files.append(item)\n",
        "    if not image_files:\n",
        "        print(f\"\\nError: No supported image files found in directory: {input_path}\")\n",
        "        exit()\n",
        "    print(f\"Found {len(image_files)} supported image files.\")\n",
        "else:\n",
        "    print(f\"Error: Input path {input_path} is neither a file nor a directory.\")\n",
        "    exit()\n",
        "\n",
        "print(f\"Files to process: {[f.name for f in image_files]}\")\n",
        "\n",
        "# Load the Model\n",
        "print(\"\\n--- Loading Model ---\")\n",
        "try:\n",
        "    model = YOLO(model_path)\n",
        "    print(\"Model loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}\")\n",
        "    exit()\n",
        "\n",
        "# Process Each Image\n",
        "print(f\"\\n--- Starting Inference Process ({len(image_files)} images) ---\")\n",
        "for image_path in tqdm(image_files, desc=\"Processing Images\"):\n",
        "    output_filename = output_dir / f\"{image_path.stem}.txt\"\n",
        "    try:\n",
        "        results = model.predict(source=image_path, conf=CONF_THRESHOLD, verbose=False, stream=False)\n",
        "        detections = []\n",
        "        if results and results[0] and results[0].boxes:\n",
        "            for box in results[0].boxes:\n",
        "                class_id = int(box.cls.item())\n",
        "                class_name = model.names[class_id]\n",
        "                confidence = box.conf.item()\n",
        "                xmin, ymin, xmax, ymax = map(float, box.xyxy.tolist()[0])\n",
        "                detections.append(f\"{class_name},{xmin:.2f},{ymin:.2f},{xmax:.2f},{ymax:.2f},{confidence:.4f}\")\n",
        "\n",
        "        with open(output_filename, 'w') as f:\n",
        "            for line in detections:\n",
        "                f.write(line + '\\n')\n",
        "        print(f\"Processed: {image_path.name} -> Saved {len(detections)} detections to {output_filename.name}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {image_path.name}: {e}\")\n",
        "        try:\n",
        "            with open(output_filename, 'w') as f:\n",
        "                f.write(f\"Error processing image: {e}\\n\")\n",
        "        except:\n",
        "            print(f\"Failed to write error message to {output_filename.name}\")\n",
        "\n",
        "print(\"\\n--- Inference finished ---\")\n",
        "print(f\"Results saved in: {output_dir}\")"
      ],
      "metadata": {
        "id": "8XhpJpTK2VVs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}